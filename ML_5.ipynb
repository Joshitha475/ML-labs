{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joshitha475/ML-labs/blob/main/ML_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "9Pb1e9unP58I",
        "outputId": "41fbf562-e952-405a-d032-39f551e682f4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-63672c19-b992-4751-8db1-12bb29ab3cc7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-63672c19-b992-4751-8db1-12bb29ab3cc7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IRIS.csv to IRIS.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'IRIS.csv': b'sepal_length,sepal_width,petal_length,petal_width,species\\r\\n5.1,3.5,1.4,0.2,Iris-setosa\\r\\n4.9,3,1.4,0.2,Iris-setosa\\r\\n4.7,3.2,1.3,0.2,Iris-setosa\\r\\n4.6,3.1,1.5,0.2,Iris-setosa\\r\\n5,3.6,1.4,0.2,Iris-setosa\\r\\n5.4,3.9,1.7,0.4,Iris-setosa\\r\\n4.6,3.4,1.4,0.3,Iris-setosa\\r\\n5,3.4,1.5,0.2,Iris-setosa\\r\\n4.4,2.9,1.4,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n5.4,3.7,1.5,0.2,Iris-setosa\\r\\n4.8,3.4,1.6,0.2,Iris-setosa\\r\\n4.8,3,1.4,0.1,Iris-setosa\\r\\n4.3,3,1.1,0.1,Iris-setosa\\r\\n5.8,4,1.2,0.2,Iris-setosa\\r\\n5.7,4.4,1.5,0.4,Iris-setosa\\r\\n5.4,3.9,1.3,0.4,Iris-setosa\\r\\n5.1,3.5,1.4,0.3,Iris-setosa\\r\\n5.7,3.8,1.7,0.3,Iris-setosa\\r\\n5.1,3.8,1.5,0.3,Iris-setosa\\r\\n5.4,3.4,1.7,0.2,Iris-setosa\\r\\n5.1,3.7,1.5,0.4,Iris-setosa\\r\\n4.6,3.6,1,0.2,Iris-setosa\\r\\n5.1,3.3,1.7,0.5,Iris-setosa\\r\\n4.8,3.4,1.9,0.2,Iris-setosa\\r\\n5,3,1.6,0.2,Iris-setosa\\r\\n5,3.4,1.6,0.4,Iris-setosa\\r\\n5.2,3.5,1.5,0.2,Iris-setosa\\r\\n5.2,3.4,1.4,0.2,Iris-setosa\\r\\n4.7,3.2,1.6,0.2,Iris-setosa\\r\\n4.8,3.1,1.6,0.2,Iris-setosa\\r\\n5.4,3.4,1.5,0.4,Iris-setosa\\r\\n5.2,4.1,1.5,0.1,Iris-setosa\\r\\n5.5,4.2,1.4,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n5,3.2,1.2,0.2,Iris-setosa\\r\\n5.5,3.5,1.3,0.2,Iris-setosa\\r\\n4.9,3.1,1.5,0.1,Iris-setosa\\r\\n4.4,3,1.3,0.2,Iris-setosa\\r\\n5.1,3.4,1.5,0.2,Iris-setosa\\r\\n5,3.5,1.3,0.3,Iris-setosa\\r\\n4.5,2.3,1.3,0.3,Iris-setosa\\r\\n4.4,3.2,1.3,0.2,Iris-setosa\\r\\n5,3.5,1.6,0.6,Iris-setosa\\r\\n5.1,3.8,1.9,0.4,Iris-setosa\\r\\n4.8,3,1.4,0.3,Iris-setosa\\r\\n5.1,3.8,1.6,0.2,Iris-setosa\\r\\n4.6,3.2,1.4,0.2,Iris-setosa\\r\\n5.3,3.7,1.5,0.2,Iris-setosa\\r\\n5,3.3,1.4,0.2,Iris-setosa\\r\\n7,3.2,4.7,1.4,Iris-versicolor\\r\\n6.4,3.2,4.5,1.5,Iris-versicolor\\r\\n6.9,3.1,4.9,1.5,Iris-versicolor\\r\\n5.5,2.3,4,1.3,Iris-versicolor\\r\\n6.5,2.8,4.6,1.5,Iris-versicolor\\r\\n5.7,2.8,4.5,1.3,Iris-versicolor\\r\\n6.3,3.3,4.7,1.6,Iris-versicolor\\r\\n4.9,2.4,3.3,1,Iris-versicolor\\r\\n6.6,2.9,4.6,1.3,Iris-versicolor\\r\\n5.2,2.7,3.9,1.4,Iris-versicolor\\r\\n5,2,3.5,1,Iris-versicolor\\r\\n5.9,3,4.2,1.5,Iris-versicolor\\r\\n6,2.2,4,1,Iris-versicolor\\r\\n6.1,2.9,4.7,1.4,Iris-versicolor\\r\\n5.6,2.9,3.6,1.3,Iris-versicolor\\r\\n6.7,3.1,4.4,1.4,Iris-versicolor\\r\\n5.6,3,4.5,1.5,Iris-versicolor\\r\\n5.8,2.7,4.1,1,Iris-versicolor\\r\\n6.2,2.2,4.5,1.5,Iris-versicolor\\r\\n5.6,2.5,3.9,1.1,Iris-versicolor\\r\\n5.9,3.2,4.8,1.8,Iris-versicolor\\r\\n6.1,2.8,4,1.3,Iris-versicolor\\r\\n6.3,2.5,4.9,1.5,Iris-versicolor\\r\\n6.1,2.8,4.7,1.2,Iris-versicolor\\r\\n6.4,2.9,4.3,1.3,Iris-versicolor\\r\\n6.6,3,4.4,1.4,Iris-versicolor\\r\\n6.8,2.8,4.8,1.4,Iris-versicolor\\r\\n6.7,3,5,1.7,Iris-versicolor\\r\\n6,2.9,4.5,1.5,Iris-versicolor\\r\\n5.7,2.6,3.5,1,Iris-versicolor\\r\\n5.5,2.4,3.8,1.1,Iris-versicolor\\r\\n5.5,2.4,3.7,1,Iris-versicolor\\r\\n5.8,2.7,3.9,1.2,Iris-versicolor\\r\\n6,2.7,5.1,1.6,Iris-versicolor\\r\\n5.4,3,4.5,1.5,Iris-versicolor\\r\\n6,3.4,4.5,1.6,Iris-versicolor\\r\\n6.7,3.1,4.7,1.5,Iris-versicolor\\r\\n6.3,2.3,4.4,1.3,Iris-versicolor\\r\\n5.6,3,4.1,1.3,Iris-versicolor\\r\\n5.5,2.5,4,1.3,Iris-versicolor\\r\\n5.5,2.6,4.4,1.2,Iris-versicolor\\r\\n6.1,3,4.6,1.4,Iris-versicolor\\r\\n5.8,2.6,4,1.2,Iris-versicolor\\r\\n5,2.3,3.3,1,Iris-versicolor\\r\\n5.6,2.7,4.2,1.3,Iris-versicolor\\r\\n5.7,3,4.2,1.2,Iris-versicolor\\r\\n5.7,2.9,4.2,1.3,Iris-versicolor\\r\\n6.2,2.9,4.3,1.3,Iris-versicolor\\r\\n5.1,2.5,3,1.1,Iris-versicolor\\r\\n5.7,2.8,4.1,1.3,Iris-versicolor\\r\\n6.3,3.3,6,2.5,Iris-virginica\\r\\n5.8,2.7,5.1,1.9,Iris-virginica\\r\\n7.1,3,5.9,2.1,Iris-virginica\\r\\n6.3,2.9,5.6,1.8,Iris-virginica\\r\\n6.5,3,5.8,2.2,Iris-virginica\\r\\n7.6,3,6.6,2.1,Iris-virginica\\r\\n4.9,2.5,4.5,1.7,Iris-virginica\\r\\n7.3,2.9,6.3,1.8,Iris-virginica\\r\\n6.7,2.5,5.8,1.8,Iris-virginica\\r\\n7.2,3.6,6.1,2.5,Iris-virginica\\r\\n6.5,3.2,5.1,2,Iris-virginica\\r\\n6.4,2.7,5.3,1.9,Iris-virginica\\r\\n6.8,3,5.5,2.1,Iris-virginica\\r\\n5.7,2.5,5,2,Iris-virginica\\r\\n5.8,2.8,5.1,2.4,Iris-virginica\\r\\n6.4,3.2,5.3,2.3,Iris-virginica\\r\\n6.5,3,5.5,1.8,Iris-virginica\\r\\n7.7,3.8,6.7,2.2,Iris-virginica\\r\\n7.7,2.6,6.9,2.3,Iris-virginica\\r\\n6,2.2,5,1.5,Iris-virginica\\r\\n6.9,3.2,5.7,2.3,Iris-virginica\\r\\n5.6,2.8,4.9,2,Iris-virginica\\r\\n7.7,2.8,6.7,2,Iris-virginica\\r\\n6.3,2.7,4.9,1.8,Iris-virginica\\r\\n6.7,3.3,5.7,2.1,Iris-virginica\\r\\n7.2,3.2,6,1.8,Iris-virginica\\r\\n6.2,2.8,4.8,1.8,Iris-virginica\\r\\n6.1,3,4.9,1.8,Iris-virginica\\r\\n6.4,2.8,5.6,2.1,Iris-virginica\\r\\n7.2,3,5.8,1.6,Iris-virginica\\r\\n7.4,2.8,6.1,1.9,Iris-virginica\\r\\n7.9,3.8,6.4,2,Iris-virginica\\r\\n6.4,2.8,5.6,2.2,Iris-virginica\\r\\n6.3,2.8,5.1,1.5,Iris-virginica\\r\\n6.1,2.6,5.6,1.4,Iris-virginica\\r\\n7.7,3,6.1,2.3,Iris-virginica\\r\\n6.3,3.4,5.6,2.4,Iris-virginica\\r\\n6.4,3.1,5.5,1.8,Iris-virginica\\r\\n6,3,4.8,1.8,Iris-virginica\\r\\n6.9,3.1,5.4,2.1,Iris-virginica\\r\\n6.7,3.1,5.6,2.4,Iris-virginica\\r\\n6.9,3.1,5.1,2.3,Iris-virginica\\r\\n5.8,2.7,5.1,1.9,Iris-virginica\\r\\n6.8,3.2,5.9,2.3,Iris-virginica\\r\\n6.7,3.3,5.7,2.5,Iris-virginica\\r\\n6.7,3,5.2,2.3,Iris-virginica\\r\\n6.3,2.5,5,1.9,Iris-virginica\\r\\n6.5,3,5.2,2,Iris-virginica\\r\\n6.2,3.4,5.4,2.3,Iris-virginica\\r\\n5.9,3,5.1,1.8,Iris-virginica\\r\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris_df = pd.read_csv('/IRIS.csv')\n",
        "print(iris_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYgZnFPMStEJ",
        "outputId": "f2271571-4d14-4eea-eeea-9bfee791b488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width      species\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "test_sizes = [0.2, 0.3]\n",
        "random_states = [42, 123]\n",
        "\n",
        "for test_size in test_sizes:\n",
        "    for random_state in random_states:\n",
        "        train_data, test_data = train_test_split(iris_df, test_size=test_size, random_state=random_state)\n",
        "        print(f\"Test Size: {test_size}, Random State: {random_state}\")\n",
        "        print(f\"Train set size: {train_data.shape}, Test set size: {test_data.shape}\")\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqBYNLuqTag3",
        "outputId": "a75a01a7-c909-4b09-b26e-393900dc9b80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Size: 0.2, Random State: 42\n",
            "Train set size: (120, 5), Test set size: (30, 5)\n",
            "\n",
            "Test Size: 0.2, Random State: 123\n",
            "Train set size: (120, 5), Test set size: (30, 5)\n",
            "\n",
            "Test Size: 0.3, Random State: 42\n",
            "Train set size: (105, 5), Test set size: (45, 5)\n",
            "\n",
            "Test Size: 0.3, Random State: 123\n",
            "Train set size: (105, 5), Test set size: (45, 5)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the dataset into Pandas DataFrame\n",
        "iris_df = pd.read_csv('/IRIS.csv')\n",
        "\n",
        "# Split the dataset into features (X) and target (y)\n",
        "X = iris_df.drop('species', axis=1)  # Features\n",
        "y = iris_df['species']              # Target\n",
        "\n",
        "# Split data into training and testing sets (for example, with test size 0.2 and random state 42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gaussian Naive Bayes classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Generate classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlBul6qXUWNH",
        "outputId": "b6b97826-223c-46fc-e9b6-84eadb69856f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "\n",
            "Classification Report:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "    Iris-setosa       1.00      1.00      1.00        10\n",
            "Iris-versicolor       1.00      1.00      1.00         9\n",
            " Iris-virginica       1.00      1.00      1.00        11\n",
            "\n",
            "       accuracy                           1.00        30\n",
            "      macro avg       1.00      1.00      1.00        30\n",
            "   weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print target classes\n",
        "target_classes = y.unique()\n",
        "print(\"Target Classes:\")\n",
        "for cls in target_classes:\n",
        "    print(cls)\n",
        "# Print conditional probabilities\n",
        "print(\"\\nConditional Probabilities (Gaussian Naive Bayes):\")\n",
        "for i, cls in enumerate(gnb.classes_):\n",
        "    print(f\"Class '{cls}':\")\n",
        "    print(f\"Prior Probability: {gnb.class_prior_[i]:.4f}\")\n",
        "    print(\"Mean (Theta):\")\n",
        "    for feature, mean in zip(X.columns, gnb.theta_[i]):\n",
        "        print(f\"{feature}: {mean:.4f}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeixlCU4WG-W",
        "outputId": "c4e270f3-d65d-4f1d-8ebc-790f25a5d08d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Classes:\n",
            "Iris-setosa\n",
            "Iris-versicolor\n",
            "Iris-virginica\n",
            "\n",
            "Conditional Probabilities (Gaussian Naive Bayes):\n",
            "Class 'Iris-setosa':\n",
            "Prior Probability: 0.3333\n",
            "Mean (Theta):\n",
            "sepal_length: 4.9900\n",
            "sepal_width: 3.4400\n",
            "petal_length: 1.4525\n",
            "petal_width: 0.2425\n",
            "\n",
            "Class 'Iris-versicolor':\n",
            "Prior Probability: 0.3417\n",
            "Mean (Theta):\n",
            "sepal_length: 5.9195\n",
            "sepal_width: 2.7707\n",
            "petal_length: 4.2415\n",
            "petal_width: 1.3220\n",
            "\n",
            "Class 'Iris-virginica':\n",
            "Prior Probability: 0.3250\n",
            "Mean (Theta):\n",
            "sepal_length: 6.5333\n",
            "sepal_width: 2.9667\n",
            "petal_length: 5.5205\n",
            "petal_width: 2.0000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "1AFliCoFCNxH",
        "outputId": "1981aac0-871b-4147-d408-c2df2a9a550a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-924aaf8a-da93-4eef-9c02-5c6575291471\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-924aaf8a-da93-4eef-9c02-5c6575291471\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving insect.csv to insect.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'insect.csv': b'color,legs,height,smell,species\\nwhite,3,short,yes,No Harm\\ngreen,2,tall,no,No Harm\\ngreen,3,short,yes,No Harm\\nwhite,3,short,yes,No Harm\\ngreen,2,short,no,Harmful\\nwhite,2,tall,no,Harmful\\nwhite,2,tall,no,Harmful\\nwhite,2,short,yes,Harmful\\n'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example path to the uploaded dataset (replace with your actual file path)\n",
        "file_path = '/content/insect.csv'\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the dataset to verify it's loaded correctly\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8F2qP9hDDTi",
        "outputId": "335efa0b-97c2-4eaf-d38a-6a44440183ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   color  legs height smell  species\n",
            "0  white     3  short   yes  No Harm\n",
            "1  green     2   tall    no  No Harm\n",
            "2  green     3  short   yes  No Harm\n",
            "3  white     3  short   yes  No Harm\n",
            "4  green     2  short    no  Harmful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example path to the uploaded dataset (replace with your actual file path)\n",
        "file_path = '/content/insect.csv'\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Set random state for reproducibility\n",
        "random_state = 42  # Replace with any integer for different splits\n",
        "\n",
        "# Split with test size 0.2 (80/20 split)\n",
        "X_train_80, X_test_80, y_train_80, y_test_80 = train_test_split(df.drop('species', axis=1),\n",
        "                                                                df['species'],\n",
        "                                                                test_size=0.2,\n",
        "                                                                random_state=random_state)\n",
        "\n",
        "# Split with test size 0.3 (70/30 split)\n",
        "X_train_70, X_test_70, y_train_70, y_test_70 = train_test_split(df.drop('species', axis=1),\n",
        "                                                                df['species'],\n",
        "                                                                test_size=0.3,\n",
        "                                                                random_state=random_state)\n",
        "\n",
        "# Print the sizes of the resulting datasets\n",
        "print(\"For 80/20 split:\")\n",
        "print(f\"Train set size: {X_train_80.shape}, Test set size: {X_test_80.shape}\")\n",
        "print()\n",
        "print(\"For 70/30 split:\")\n",
        "print(f\"Train set size: {X_train_70.shape}, Test set size: {X_test_70.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZnuFhikQDNlM",
        "outputId": "b0dcb8b1-eb2f-4bd1-98ff-67662c977452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 80/20 split:\n",
            "Train set size: (6, 4), Test set size: (2, 4)\n",
            "\n",
            "For 70/30 split:\n",
            "Train set size: (5, 4), Test set size: (3, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Encode categorical target variable 'species'\n",
        "label_encoder = LabelEncoder()\n",
        "df['species_encoded'] = label_encoder.fit_transform(df['species'])\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop(['species', 'species_encoded'], axis=1)  # Drop both original and encoded target columns\n",
        "y = df['species_encoded']\n",
        "\n",
        "# Display the first few rows of X and y to verify encoding\n",
        "print(\"Encoded Target:\")\n",
        "print(y.head())\n",
        "print()\n",
        "print(\"Features (X):\")\n",
        "print(X.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7RpgFnlDhWt",
        "outputId": "96452efc-9f09-4f8a-fe05-5e423ebe0bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Target:\n",
            "0    1\n",
            "1    1\n",
            "2    1\n",
            "3    1\n",
            "4    0\n",
            "Name: species_encoded, dtype: int64\n",
            "\n",
            "Features (X):\n",
            "   color  legs height smell\n",
            "0  white     3  short   yes\n",
            "1  green     2   tall    no\n",
            "2  green     3  short   yes\n",
            "3  white     3  short   yes\n",
            "4  green     2  short    no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Assuming df is your DataFrame and 'species' is the target variable\n",
        "\n",
        "# Step 1: Encode the target variable if not already encoded\n",
        "label_encoder = LabelEncoder()\n",
        "df['species_encoded'] = label_encoder.fit_transform(df['species'])\n",
        "\n",
        "# Step 2: Calculate target class probabilities\n",
        "target_probabilities = df['species_encoded'].value_counts(normalize=True)\n",
        "print(\"Target Class Probabilities:\")\n",
        "print(target_probabilities)\n",
        "\n",
        "# Step 3: Calculate conditional probabilities for each attribute given the target class\n",
        "conditional_probabilities = {}\n",
        "\n",
        "for column in df.columns:\n",
        "    if column != 'species_encoded' and column != 'species':  # Skip the target columns themselves\n",
        "        conditional_probabilities[column] = df.groupby(['species_encoded', column]).size() / df.groupby('species_encoded').size()\n",
        "\n",
        "# Display the conditional probabilities in a table format\n",
        "for attribute, prob in conditional_probabilities.items():\n",
        "    print(f\"\\nConditional Probabilities for {attribute}:\")\n",
        "    print(prob.unstack().fillna(0))  # Convert to a readable format and replace NaN with 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPcRhsLwEE21",
        "outputId": "0f5e8559-0d00-4fdb-e429-5e3c3691c5e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Class Probabilities:\n",
            "species_encoded\n",
            "1    0.5\n",
            "0    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Conditional Probabilities for color:\n",
            "color            green  white\n",
            "species_encoded              \n",
            "0                 0.25   0.75\n",
            "1                 0.50   0.50\n",
            "\n",
            "Conditional Probabilities for legs:\n",
            "legs                2     3\n",
            "species_encoded            \n",
            "0                1.00  0.00\n",
            "1                0.25  0.75\n",
            "\n",
            "Conditional Probabilities for height:\n",
            "height           short  tall\n",
            "species_encoded             \n",
            "0                 0.50  0.50\n",
            "1                 0.75  0.25\n",
            "\n",
            "Conditional Probabilities for smell:\n",
            "smell              no   yes\n",
            "species_encoded            \n",
            "0                0.75  0.25\n",
            "1                0.25  0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Example DataFrame\n",
        "data = {\n",
        "    'color': ['W', 'W', 'W', 'G', 'G', 'G', 'W', 'G'],\n",
        "    'legs': [2, 2, 4, 4, 2, 4, 4, 4],\n",
        "    'height': ['short', 'tall', 'short', 'tall', 'short', 'short', 'tall', 'tall'],\n",
        "    'species': ['N.H', 'N.H', 'N.H', 'N.H', 'H', 'H', 'H', 'H']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Encode the target variable 'species'\n",
        "label_encoder = LabelEncoder()\n",
        "df['species_encoded'] = label_encoder.fit_transform(df['species'])\n",
        "\n",
        "# Step 2: Calculate the target class probabilities\n",
        "target_probabilities = df['species_encoded'].value_counts(normalize=True)\n",
        "target_prob_df = pd.DataFrame(target_probabilities).transpose()\n",
        "target_prob_df.index = [\"Class Probabilities\"]\n",
        "\n",
        "# Step 3: Calculate conditional probabilities for each attribute given the target class\n",
        "conditional_probabilities = {}\n",
        "for column in df.columns:\n",
        "    if column != 'species_encoded' and column != 'species':  # Skip the target columns\n",
        "        conditional_probabilities[column] = df.groupby(['species_encoded', column]).size() / df.groupby('species_encoded').size()\n",
        "\n",
        "# Step 4: Display the results in tables\n",
        "tables = {}\n",
        "for attribute, prob in conditional_probabilities.items():\n",
        "    tables[attribute] = prob.unstack().fillna(0)\n",
        "\n",
        "# Display the tables\n",
        "print(\"Target Class Probabilities:\")\n",
        "print(target_prob_df)\n",
        "print(\"\\nConditional Probabilities:\")\n",
        "\n",
        "for attribute, table in tables.items():\n",
        "    print(f\"\\n{attribute.capitalize()}:\")\n",
        "    print(table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oymGQwmBEcbP",
        "outputId": "bc83bb7a-7424-46c6-c462-949d9fe28f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Class Probabilities:\n",
            "species_encoded        1    0\n",
            "Class Probabilities  0.5  0.5\n",
            "\n",
            "Conditional Probabilities:\n",
            "\n",
            "Color:\n",
            "color               G     W\n",
            "species_encoded            \n",
            "0                0.75  0.25\n",
            "1                0.25  0.75\n",
            "\n",
            "Legs:\n",
            "legs                2     4\n",
            "species_encoded            \n",
            "0                0.25  0.75\n",
            "1                0.50  0.50\n",
            "\n",
            "Height:\n",
            "height           short  tall\n",
            "species_encoded             \n",
            "0                  0.5   0.5\n",
            "1                  0.5   0.5\n"
          ]
        }
      ]
    }
  ]
}